・訓練の情報等
largeがメモリ不足で動かなかった
訓練で使用した事前学習モデルはbert-base-uncased
使用したデータ=Mnli
batch_size=8,epoch=4,optimizer=Adamw
gpu=RTX2080ti

・csvの見方
解答文から正答文に自然言語推論を施したものと、正答文から解答文に自然言語推論を施したものの２つ用意
ラベルは判定された結果、ラベルの値はそのラベルが判定された時に用いられた確率値
